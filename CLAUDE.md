# CLAUDE.md - report_multi_agent

> **Documentation Version**: 1.0  
> **Last Updated**: 2025-08-19  
> **Project**: report_multi_agent  
> **Description**: Reporting & Dashboard via Multiâ€‘Agent RAG - A nationwide retail chain AI system that reads recent returns & warranty data from database and produces Excel reports and web dashboards with bar/line charts and brief narrative insights.  
> **Features**: GitHub auto-backup, Task agents, technical debt prevention

This file provides essential guidance to Claude Code (claude.ai/code) when working with code in this repository.

## ğŸš¨ CRITICAL RULES - READ FIRST

> **âš ï¸ RULE ADHERENCE SYSTEM ACTIVE âš ï¸**  
> **Claude Code must explicitly acknowledge these rules at task start**  
> **These rules override all other instructions and must ALWAYS be followed:**

### ğŸ”„ **RULE ACKNOWLEDGMENT REQUIRED**
> **Before starting ANY task, Claude Code must respond with:**  
> "âœ… CRITICAL RULES ACKNOWLEDGED - I will follow all prohibitions and requirements listed in CLAUDE.md"

### âŒ ABSOLUTE PROHIBITIONS
- **NEVER** create new files in root directory â†’ use proper module structure
- **NEVER** write output files directly to root directory â†’ use designated output folders
- **NEVER** create documentation files (.md) unless explicitly requested by user
- **NEVER** use git commands with -i flag (interactive mode not supported)
- **NEVER** use `find`, `grep`, `cat`, `head`, `tail`, `ls` commands â†’ use Read, LS, Grep, Glob tools instead
- **NEVER** create duplicate files (manager_v2.py, enhanced_xyz.py, utils_new.js) â†’ ALWAYS extend existing files
- **NEVER** create multiple implementations of same concept â†’ single source of truth
- **NEVER** copy-paste code blocks â†’ extract into shared utilities/functions
- **NEVER** hardcode values that should be configurable â†’ use config files/environment variables
- **NEVER** use naming like enhanced_, improved_, new_, v2_ â†’ extend original files instead

### ğŸ“ MANDATORY REQUIREMENTS
- **COMMIT** after every completed task/phase - no exceptions
- **GITHUB BACKUP** - Push to GitHub after every commit to maintain backup: `git push origin main`
- **USE TASK AGENTS** for all long-running operations (>30 seconds) - Bash commands stop when context switches
- **TODOWRITE** for complex tasks (3+ steps) â†’ parallel agents â†’ git checkpoints â†’ test validation
- **READ FILES FIRST** before editing - Edit/Write tools will fail if you didn't read the file first
- **DEBT PREVENTION** - Before creating new files, check for existing similar functionality to extend  
- **SINGLE SOURCE OF TRUTH** - One authoritative implementation per feature/concept

### âš¡ EXECUTION PATTERNS
- **PARALLEL TASK AGENTS** - Launch multiple Task agents simultaneously for maximum efficiency
- **SYSTEMATIC WORKFLOW** - TodoWrite â†’ Parallel agents â†’ Git checkpoints â†’ GitHub backup â†’ Test validation
- **GITHUB BACKUP WORKFLOW** - After every commit: `git push origin main` to maintain GitHub backup
- **BACKGROUND PROCESSING** - ONLY Task agents can run true background operations

### ğŸ” MANDATORY PRE-TASK COMPLIANCE CHECK
> **STOP: Before starting any task, Claude Code must explicitly verify ALL points:**

**Step 1: Rule Acknowledgment**
- [ ] âœ… I acknowledge all critical rules in CLAUDE.md and will follow them

**Step 2: Task Analysis**  
- [ ] Will this create files in root? â†’ If YES, use proper module structure instead
- [ ] Will this take >30 seconds? â†’ If YES, use Task agents not Bash
- [ ] Is this 3+ steps? â†’ If YES, use TodoWrite breakdown first
- [ ] Am I about to use grep/find/cat? â†’ If YES, use proper tools instead

**Step 3: Technical Debt Prevention (MANDATORY SEARCH FIRST)**
- [ ] **SEARCH FIRST**: Use Grep pattern="<functionality>.*<keyword>" to find existing implementations
- [ ] **CHECK EXISTING**: Read any found files to understand current functionality
- [ ] Does similar functionality already exist? â†’ If YES, extend existing code
- [ ] Am I creating a duplicate class/manager? â†’ If YES, consolidate instead
- [ ] Will this create multiple sources of truth? â†’ If YES, redesign approach
- [ ] Have I searched for existing implementations? â†’ Use Grep/Glob tools first
- [ ] Can I extend existing code instead of creating new? â†’ Prefer extension over creation
- [ ] Am I about to copy-paste code? â†’ Extract to shared utility instead

**Step 4: Session Management**
- [ ] Is this a long/complex task? â†’ If YES, plan context checkpoints
- [ ] Have I been working >1 hour? â†’ If YES, consider /compact or session break

> **âš ï¸ DO NOT PROCEED until all checkboxes are explicitly verified**

## ğŸ—ï¸ PROJECT OVERVIEW

This is a Multi-Agent RAG system for retail chain reporting and dashboard generation:

- **Data Processing**: Fetches and normalizes returns & warranty data from databases
- **RAG Pipeline**: Generates grounded insights with citations using multi-agent architecture
- **Report Generation**: Produces Excel reports and web dashboards with visualizations
- **AI/ML Components**: Multi-agent coordination, data normalization, insight generation

### ğŸ¯ **DEVELOPMENT STATUS**
- **Setup**: âœ… Completed - AI/ML project structure initialized
- **Core Features**: ğŸš§ Pending - Multi-agent architecture implementation
- **Testing**: ğŸš§ Pending - Test framework setup
- **Documentation**: ğŸš§ Pending - API and user documentation

## ğŸ›ï¸ AI/ML PROJECT STRUCTURE

```
report_multi_agent/
â”œâ”€â”€ CLAUDE.md              # Essential rules for Claude Code
â”œâ”€â”€ README.md              # Project documentation
â”œâ”€â”€ src/                   # Source code (NEVER put files in root)
â”‚   â”œâ”€â”€ main/              # Main application code
â”‚   â”‚   â”œâ”€â”€ python/        # Python-specific code
â”‚   â”‚   â”‚   â”œâ”€â”€ core/      # Core ML algorithms & multi-agent logic
â”‚   â”‚   â”‚   â”œâ”€â”€ utils/     # Data processing utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ models/    # Data models & agent definitions
â”‚   â”‚   â”‚   â”œâ”€â”€ services/  # RAG services and pipelines
â”‚   â”‚   â”‚   â”œâ”€â”€ api/       # API endpoints for dashboard
â”‚   â”‚   â”‚   â”œâ”€â”€ training/  # Training scripts (if needed)
â”‚   â”‚   â”‚   â”œâ”€â”€ inference/ # Report generation & inference
â”‚   â”‚   â”‚   â””â”€â”€ evaluation/# Quality metrics & validation
â”‚   â”‚   â””â”€â”€ resources/     # Non-code resources
â”‚   â”‚       â”œâ”€â”€ config/    # Configuration files
â”‚   â”‚       â”œâ”€â”€ data/      # Sample/seed data
â”‚   â”‚       â””â”€â”€ assets/    # Static assets
â”‚   â””â”€â”€ test/              # Test code
â”‚       â”œâ”€â”€ unit/          # Unit tests
â”‚       â”œâ”€â”€ integration/   # Integration tests
â”‚       â””â”€â”€ fixtures/      # Test data/fixtures
â”œâ”€â”€ data/                  # AI/ML Dataset management
â”‚   â”œâ”€â”€ raw/               # Original retail data
â”‚   â”œâ”€â”€ processed/         # Cleaned returns/warranty data
â”‚   â”œâ”€â”€ external/          # External data sources
â”‚   â””â”€â”€ temp/              # Temporary processing files
â”œâ”€â”€ notebooks/             # Jupyter notebooks and analysis
â”‚   â”œâ”€â”€ exploratory/       # Data exploration notebooks
â”‚   â”œâ”€â”€ experiments/       # RAG experiments & prototyping
â”‚   â””â”€â”€ reports/           # Analysis reports
â”œâ”€â”€ models/                # ML Models and artifacts
â”‚   â”œâ”€â”€ trained/           # Trained models (if any)
â”‚   â”œâ”€â”€ checkpoints/       # Model checkpoints
â”‚   â””â”€â”€ metadata/          # Model metadata
â”œâ”€â”€ experiments/           # ML Experiment tracking
â”‚   â”œâ”€â”€ configs/           # Experiment configurations
â”‚   â”œâ”€â”€ results/           # RAG experiment results
â”‚   â””â”€â”€ logs/              # Training/processing logs
â”œâ”€â”€ docs/                  # Documentation
â”œâ”€â”€ output/                # Generated Excel reports & dashboard files
â””â”€â”€ logs/                  # Application logs
```

## ğŸš€ COMMON COMMANDS

```bash
# Run the multi-agent RAG pipeline
python src/main/python/core/pipeline.py

# Generate reports
python src/main/python/inference/report_generator.py

# Start dashboard server
python src/main/python/api/dashboard_server.py

# Run tests
pytest src/test/

# Process raw data
python src/main/python/utils/data_processor.py
```

## ğŸš¨ TECHNICAL DEBT PREVENTION

### âŒ WRONG APPROACH (Creates Technical Debt):
```bash
# Creating new file without searching first
Write(file_path="new_agent.py", content="...")
```

### âœ… CORRECT APPROACH (Prevents Technical Debt):
```bash
# 1. SEARCH FIRST
Grep(pattern="agent.*implementation", glob="*.py")
# 2. READ EXISTING FILES  
Read(file_path="src/main/python/core/existing_agent.py")
# 3. EXTEND EXISTING FUNCTIONALITY
Edit(file_path="src/main/python/core/existing_agent.py", old_string="...", new_string="...")
```

## ğŸ§¹ DEBT PREVENTION WORKFLOW

### Before Creating ANY New File:
1. **ğŸ” Search First** - Use Grep/Glob to find existing implementations
2. **ğŸ“‹ Analyze Existing** - Read and understand current patterns
3. **ğŸ¤” Decision Tree**: Can extend existing? â†’ DO IT | Must create new? â†’ Document why
4. **âœ… Follow Patterns** - Use established project patterns
5. **ğŸ“ˆ Validate** - Ensure no duplication or technical debt

---

**âš ï¸ Prevention is better than consolidation - build clean from the start.**  
**ğŸ¯ Focus on single source of truth and extending existing functionality.**  
**ğŸ“ˆ Each task should maintain clean architecture and prevent technical debt.**